{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Toolkit for Splunk - SVM GridSearch with MLflow Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example workflow how to work on an SVM model that receives a range of parameters to test using GridSearch to find the optimum SVM model and track the experiment in MLflow using the Deep Learning Toolkit for Splunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: By default every time you save this notebook the cells are exported into a python module which is then invoked by Splunk MLTK commands like <code> | fit ... | apply ... | summary </code>. Please read the Model Development Guide in the Deep Learning Toolkit app for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import sklearn\n",
    "# ...\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.19.2\n",
      "pandas version: 1.1.3\n",
      "sklearn version: 0.22.2\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"sklearn version: \" + sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a dataset into your notebook environment. Note: mode=stage is used in the | fit command to do this. This example uses the housing.csv data loaded with the MLTK.\n",
    "\n",
    "The GridSearch utilizes a range of parameters for the model, and tests all possible combinations of those parameters to find the set that provides the best results. In your Splunk search, you define your set of parameters to test your SVM model with by using the <b>grid</b> keyword. Wrap the full grid in double-quotes, and individual parameter test sets in curly-brackets.  In the example below, the linear kernel will be tested with C values of 10, 300 and 1000; and the rbf kernel will be tested with C values of 1, 10, and 1000, and gamma values of .01, 1, and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup housing.csv<br/>\n",
    "| fit MLTKContainer mode=stage algo=grid_search_svm grid=\"{'kernel': ['linear'], 'C': [10., 300., 1000.]},{'kernel': ['rbf'], 'C': [1.0, 10., 1000.0],'gamma': [0.01, 1.0, 3.0]},\" median_house_value from avg_rooms_per_dwelling, business_acres, charles_river_adjacency, crime_rate, distance_to_employment_center, highway_accessibility_index, land_zone, nitric_oxide_concentration, property_tax_rate, pupil_teacher_ratio, units_prior_1940 into app:svm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"svm_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'options': {'params': {'mode': 'stage', 'algo': 'grid_search_svm', 'grid': '\"{\\'kernel\\': [\\'linear\\'], \\'C\\': [10., 300., 1000.]},{\\'kernel\\': [\\'rbf\\'], \\'C\\': [1.0, 10., 1000.0],\\'gamma\\': [0.01, 1.0, 3.0]},\"'}, 'args': ['median_house_value', 'avg_rooms_per_dwelling', 'business_acres', 'charles_river_adjacency', 'crime_rate', 'distance_to_employment_center', 'highway_accessibility_index', 'land_zone', 'nitric_oxide_concentration', 'property_tax_rate', 'pupil_teacher_ratio', 'units_prior_1940'], 'target_variable': ['median_house_value'], 'feature_variables': ['avg_rooms_per_dwelling', 'business_acres', 'charles_river_adjacency', 'crime_rate', 'distance_to_employment_center', 'highway_accessibility_index', 'land_zone', 'nitric_oxide_concentration', 'property_tax_rate', 'pupil_teacher_ratio', 'units_prior_1940'], 'model_name': 'svm_model', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'disabled': False, 'handle_new_cat': 'default', 'max_distinct_cat_values': '10000', 'max_distinct_cat_values_for_classifiers': '10000', 'max_distinct_cat_values_for_scoring': '10000', 'max_fit_time': '6000', 'max_inputs': '100000000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '150', 'max_score_time': '6000', 'streaming_apply': '0', 'use_sampling': '1'}, 'kfold_cv': None}, 'feature_variables': ['avg_rooms_per_dwelling', 'business_acres', 'charles_river_adjacency', 'crime_rate', 'distance_to_employment_center', 'highway_accessibility_index', 'land_zone', 'nitric_oxide_concentration', 'property_tax_rate', 'pupil_teacher_ratio', 'units_prior_1940'], 'target_variables': ['median_house_value']}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"svm_model\")\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>land_zone</th>\n",
       "      <th>business_acres</th>\n",
       "      <th>charles_river_adjacency</th>\n",
       "      <th>nitric_oxide_concentration</th>\n",
       "      <th>avg_rooms_per_dwelling</th>\n",
       "      <th>units_prior_1940</th>\n",
       "      <th>distance_to_employment_center</th>\n",
       "      <th>highway_accessibility_index</th>\n",
       "      <th>property_tax_rate</th>\n",
       "      <th>pupil_teacher_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.532806</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.197104</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.025000</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.200000</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.677082</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       median_house_value  crime_rate   land_zone  business_acres  \\\n",
       "count          506.000000  506.000000  506.000000      506.000000   \n",
       "mean            22.532806    3.613524   11.363636       11.136779   \n",
       "std              9.197104    8.601545   23.322453        6.860353   \n",
       "min              5.000000    0.006320    0.000000        0.460000   \n",
       "25%             17.025000    0.082045    0.000000        5.190000   \n",
       "50%             21.200000    0.256510    0.000000        9.690000   \n",
       "75%             25.000000    3.677082   12.500000       18.100000   \n",
       "max             50.000000   88.976200  100.000000       27.740000   \n",
       "\n",
       "       charles_river_adjacency  nitric_oxide_concentration  \\\n",
       "count               506.000000                  506.000000   \n",
       "mean                  0.069170                    0.554695   \n",
       "std                   0.253994                    0.115878   \n",
       "min                   0.000000                    0.385000   \n",
       "25%                   0.000000                    0.449000   \n",
       "50%                   0.000000                    0.538000   \n",
       "75%                   0.000000                    0.624000   \n",
       "max                   1.000000                    0.871000   \n",
       "\n",
       "       avg_rooms_per_dwelling  units_prior_1940  \\\n",
       "count              506.000000        506.000000   \n",
       "mean                 6.284634         68.574901   \n",
       "std                  0.702617         28.148861   \n",
       "min                  3.561000          2.900000   \n",
       "25%                  5.885500         45.025000   \n",
       "50%                  6.208500         77.500000   \n",
       "75%                  6.623500         94.075000   \n",
       "max                  8.780000        100.000000   \n",
       "\n",
       "       distance_to_employment_center  highway_accessibility_index  \\\n",
       "count                     506.000000                   506.000000   \n",
       "mean                        3.795043                     9.549407   \n",
       "std                         2.105710                     8.707259   \n",
       "min                         1.129600                     1.000000   \n",
       "25%                         2.100175                     4.000000   \n",
       "50%                         3.207450                     5.000000   \n",
       "75%                         5.188425                    24.000000   \n",
       "max                        12.126500                    24.000000   \n",
       "\n",
       "       property_tax_rate  pupil_teacher_ratio  \n",
       "count         506.000000           506.000000  \n",
       "mean          408.237154            18.455534  \n",
       "std           168.537116             2.164946  \n",
       "min           187.000000            12.600000  \n",
       "25%           279.000000            17.400000  \n",
       "50%           330.000000            19.050000  \n",
       "75%           666.000000            20.200000  \n",
       "max           711.000000            22.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Once you have your data loaded, you can do some exploratory data analysis directly in the notebook.  See the plots below visualizing the variables in this data set. These images can be saved and included inside of Splunk dashboards as well.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "median_house_value               1.000000\n",
       "avg_rooms_per_dwelling           0.695360\n",
       "land_zone                        0.360445\n",
       "distance_to_employment_center    0.249929\n",
       "charles_river_adjacency          0.175260\n",
       "units_prior_1940                -0.376955\n",
       "highway_accessibility_index     -0.381626\n",
       "crime_rate                      -0.388305\n",
       "nitric_oxide_concentration      -0.427321\n",
       "property_tax_rate               -0.468536\n",
       "business_acres                  -0.483725\n",
       "pupil_teacher_ratio             -0.507787\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"avg_rooms_per_dwelling\", \"land_zone\",\n",
    "              \"distance_to_employment_center\"]\n",
    "scatter_matrix(df[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=\"avg_rooms_per_dwelling\", y=\"median_house_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "def log_run(gridsearch: GridSearchCV, experiment_name: str, model_name: str, run_index: int, conda_env, tags={}):\n",
    "    \"\"\"Logging of scikit learn grid search cross validation results to mlflow tracking server\n",
    "\n",
    "    Arguments:\n",
    "        experiment_name (str): experiment name\n",
    "        model_name (str): Name of the model\n",
    "        run_index (int): Index of the run (in Gridsearch)\n",
    "        conda_env (str): A dictionary that describes the conda environment (MLFlow Format)\n",
    "        tags (dict): Dictionary of extra data and tags (usually features)\n",
    "    \"\"\"\n",
    "    \n",
    "    cv_results = gridsearch.cv_results_\n",
    "    with mlflow.start_run(run_name=str(run_index)) as run:  \n",
    "\n",
    "        mlflow.log_param(\"folds\", gridsearch.cv)\n",
    "\n",
    "        #print(\"Logging parameters\")       \n",
    "        for grid in gridsearch.param_grid:\n",
    "            params = list(grid.keys())\n",
    "            for param in params:\n",
    "                mlflow.log_param(param, cv_results[\"param_%s\" % param][run_index])\n",
    "\n",
    "        #print(\"Logging metrics\")\n",
    "        for score_name in [score for score in cv_results if \"mean_test\" in score]:\n",
    "            mlflow.log_metric(score_name, cv_results[score_name][run_index])\n",
    "            mlflow.log_metric(score_name.replace(\"mean\",\"std\"), cv_results[score_name.replace(\"mean\",\"std\")][run_index])\n",
    "\n",
    "        #print(\"Logging model\")        \n",
    "        mlflow.sklearn.log_model(gridsearch.best_estimator_, model_name) #, conda_env=conda_env)\n",
    "\n",
    "        #print(\"Logging extra data related to the experiment\")\n",
    "        mlflow.set_tags(tags) \n",
    "\n",
    "        run_id = run.info.run_uuid\n",
    "        experiment_id = run.info.experiment_id\n",
    "        mlflow.end_run()\n",
    "        \n",
    "        #print(mlflow.get_artifact_uri())\n",
    "        #print(\"runID: %s\" % run_id)\n",
    "\n",
    "def split_dataframe(df,param):\n",
    "    # separate target variable and feature variables\n",
    "    df_labels = np.ravel(df[param['options']['target_variable']])\n",
    "    df_features = df[param['options']['feature_variables']]\n",
    "    return df_labels,df_features\n",
    "\n",
    "def run_grid_search(df, param):\n",
    "    df_labels,df_features = split_dataframe(df,param)\n",
    "    #get GridSearch parameters from Splunk search\n",
    "    my_grid = param['options']['params']['grid']\n",
    "    my_grid = my_grid.strip('\\\"')\n",
    "    res = re.findall(r'\\{.*?\\}', my_grid)\n",
    "    array_res = np.array(res)\n",
    "    param_grid=[]\n",
    "    for x in res:\n",
    "        param_grid.append(eval(x))\n",
    "\n",
    "    #define model\n",
    "    model = SVR()\n",
    "\n",
    "    # Perform gridsearch of model with parameters that have been passed to identify the best performing model parameters.\n",
    "    #\n",
    "    # Note: a gridsearch can be very compute intensive. The job below has n_jobs set to -1 which utilizes all of the \n",
    "    # available cores to process the search in parallel. Remove that parameter to process single-threaded (this will \n",
    "    # significantly increase processing time), or change to another value to specify how many processes can run in parallel.\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(df_features, df_labels)\n",
    "    \n",
    "    # Log all metrics of the gridsearch results into mlflow experiment\n",
    "    experiment_name = \"Gridsearch SVM\"\n",
    "    model_name = param['options']['model_name']\n",
    "    conda_env = {\n",
    "        'name': 'mlflow-env',\n",
    "        'channels': ['defaults'],\n",
    "        'dependencies': [\n",
    "            'python=3.8.5',\n",
    "            'scikit-learn>=0.22.2',\n",
    "        ]\n",
    "    }\n",
    "    tags = {}\n",
    "    mlflow.set_tracking_uri(\"http://localhost:6000\")\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    for i in range(len(grid_search.cv_results_['params'])):\n",
    "        log_run(grid_search, experiment_name, model_name, i, conda_env, tags)\n",
    "    \n",
    "    # return the best estimator\n",
    "    model = grid_search.best_estimator_\n",
    "    return model\n",
    "\n",
    "# initialize final model\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "\n",
    "def init(df,param):\n",
    "    model=run_grid_search(df,param)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'Gridsearch SVM' does not exist. Creating a new experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "Logging parameters\n",
      "Logging metrics\n",
      "Logging model\n",
      "Logging extra data related to the experiment\n",
      "SVR(C=10.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
      "    kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model=init(df,param)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):\n",
    "    df_labels,df_features = split_dataframe(df,param)\n",
    "    model.fit(df_features, df_labels)\n",
    "    info = {\"message\": \"model trained\"}\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'model trained'}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# apply your model\n",
    "# returns the calculated results\n",
    "def apply(model,df,param):\n",
    "    X = df[param['feature_variables']]\n",
    "    y_hat = model.predict(X)\n",
    "    result = pd.DataFrame(y_hat)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0\n",
      "0     0.978313\n",
      "1    21.739175\n",
      "2    30.665977\n",
      "3    29.203668\n",
      "4    12.654771\n",
      "..         ...\n",
      "501  17.013751\n",
      "502  15.229628\n",
      "503  32.668137\n",
      "504  16.797954\n",
      "505  23.730751\n",
      "\n",
      "[506 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(apply(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>\"\n",
    "def save(model,name):\n",
    "    file = MODEL_DIRECTORY + name + \".pkl\"\n",
    "    joblib.dump(model, file) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=10.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "    kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=\"svm_model\"\n",
    "save(model,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>\"\n",
    "def load(name):\n",
    "    file = MODEL_DIRECTORY + name + \".pkl\"\n",
    "    model = joblib.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
